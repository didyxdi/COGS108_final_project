{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan as Nan\n",
    "import xml.etree.ElementTree as ET # to read one dataset in XML format\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import requests\n",
    "from string import digits\n",
    "import wget \n",
    "import glob\n",
    "import time\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind, chisquare, normaltest\n",
    "import patsy\n",
    "import psutil\n",
    "\n",
    "import plotly.graph_objects as go # to draw geospatial maps\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the correlation between unpleasant flight status (delay, cancellation and diversion) and airports where flights start and end in the U.S., we need to aggregate comprehensive airport attributes and main outcome variables (delay, cancellation and diversion). Thus, in the Data Cleaning step, our goal is to wrangle useful data from collected datasets and forge them into two dataframes whose indices are distinct 3-digit airport codes of airports in the U.S. (e.g. ABE) with the following columns:\n",
    "\n",
    "   1. `merged_X`: attributes of each airport (23 columns)\n",
    "         - total_departure: total number of flights originated from this airport \n",
    "         - total_arrival: total number of flights arriving at this airport\n",
    "         - departure_distance_avg: average distance of all flights originated from this airport\n",
    "         - arrival_distance_avg: average distance of all flights arriving at this airport\n",
    "         - departure_taxi_avg: average taxi time of all flights originated from this airport\n",
    "         - arrival_taxi_avg: average taxi time of all flights arriving at this airport\n",
    "         - city_name: city where the airport locates\n",
    "         - code4: 4-digit airport code\n",
    "         - latitude: latitude of the airport\n",
    "         - longitude: longitude of the airport\n",
    "         - altitude_ft: altitude of the airport\n",
    "         - city_id: index of this city in uscities_df\n",
    "         - fips: county-level FIPS code of the airport\n",
    "         - population: population of the city near the airport\n",
    "         - temp_avg: average tempreature of the county contining the airport in 2018\n",
    "         - pcp_avg: average precipitation of the county contining the airport in 2018\n",
    "         - strike_avg: year-average number bird strike (may not caused damage) during 2000~2011\n",
    "         - damage_avg: year-average number of bird strike that caused damage during 2000~2011\n",
    "         - enplanements: enplanements of the city near the airport in 2018\n",
    "         - length_ft_sum: total length of all runways in the airport\n",
    "         - width_ft_avg: average width of all runways in the airport\n",
    "         - runway_count: number of runways in the airport\n",
    "         - security_avg: average security wait time of the airport\n",
    "         \n",
    "         \n",
    "   2. `Y`: unpleasant flight status of each airport.\n",
    "         - departure_delay_avg: average delay of all flights originated from this airport \n",
    "         - arrival_delay_avg: average delay of all flights arriving at this airport\n",
    "         - cancelled_avg: average cancel rate of all flights originated from this airport\n",
    "         - diverte_avg: average diverted rate of all flights arriving at this airport\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 'total_departure', 'total_arrival', 'departure_distance_avg', 'arrival_distance_avg', 'departure_taxi_avg', 'arrival_taxi_avg' of `merged_X` and all columns of `Y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `datasets/original/delay/2018.csv` which describes detailed unpleasant information of each flight in the U.S.. For the purpose of research question, we select useful columns and transform flight info to airport info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_2018_df = pd.read_csv(\"datasets/original/delay/2018.csv\") # dataset 1\n",
    "delay_2018_df = delay_2018_df[[\"ORIGIN\",\"DEST\",\"DEP_DELAY\",\"TAXI_OUT\",\"CANCELLED\",\"DISTANCE\",\"ARR_DELAY\",\"TAXI_IN\",\"DIVERTED\"]] # columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>DIVERTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>EWR</td>\n",
       "      <td>DEN</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LAS</td>\n",
       "      <td>SFO</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SNA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RSW</td>\n",
       "      <td>ORD</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ORD</td>\n",
       "      <td>ALB</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORIGIN DEST  DEP_DELAY  TAXI_OUT  CANCELLED  DISTANCE  ARR_DELAY  TAXI_IN  \\\n",
       "0    EWR  DEN       -5.0      15.0        0.0    1605.0      -23.0     10.0   \n",
       "1    LAS  SFO       -8.0      11.0        0.0     414.0      -24.0      7.0   \n",
       "2    SNA  DEN       -5.0      15.0        0.0     846.0      -13.0      5.0   \n",
       "3    RSW  ORD        6.0      19.0        0.0    1120.0       -2.0      6.0   \n",
       "4    ORD  ALB       20.0      13.0        0.0     723.0       14.0     10.0   \n",
       "\n",
       "   DIVERTED  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_2018_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First,we check the distribution of missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORIGIN            0\n",
       "DEST              0\n",
       "DEP_DELAY    117234\n",
       "TAXI_OUT     115830\n",
       "CANCELLED         0\n",
       "DISTANCE          0\n",
       "ARR_DELAY    137040\n",
       "TAXI_IN      119246\n",
       "DIVERTED          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_2018_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values for delay columns. However, we discovered that 95% of the missing value have \"CANCALLED\" == 1. It is logical to have missing delay value when the flight is never done. For these flight have already contributed to the cancel rate feature, thus should not have a effect on the delay. Since we are using the .mean() function, which will ignore all nan values, we left these rows unchanged. Same for diverted, when there shouldn't be a arrival delay because the flight is not arriving at the scheduled airport. We kept them because we can have a more accurate total departure/arrival number. In this way we have only 4000 rows that we can't explain the reason behind missing value. Since we have 7213446 rows in total, 4000 is a acceptable amount of missing. We also kept it for accurate total departure/arrival number.\n",
    "We then calculated departure_delay, arrival_delay and other columns of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate total_departure, departure_delay_avg, departure_taxi_avg, departure_cancelled_avg, departure_distance_avg data by counting flights with target airport as originated airport\n",
    "unpleasant_2018_departure = pd.DataFrame()\n",
    "unpleasant_2018_departure['total_departure'] = delay_2018_df.loc[:,[\"ORIGIN\"]].groupby('ORIGIN').size()\n",
    "unpleasant_2018_departure[[\"departure_delay_avg\",\"departure_taxi_avg\"]] = delay_2018_df.loc[:,[\"ORIGIN\",\"DEP_DELAY\",\"TAXI_OUT\"]].groupby('ORIGIN').mean()\n",
    "unpleasant_2018_departure['departure_cancelled_avg'] = delay_2018_df.loc[:,[\"ORIGIN\",\"CANCELLED\"]].groupby('ORIGIN').mean()\n",
    "unpleasant_2018_departure['departure_distance_avg'] = delay_2018_df.loc[:,[\"ORIGIN\",\"DISTANCE\"]].groupby('ORIGIN').mean()\n",
    "    \n",
    "# Generate total_arrival, arrival_delay_avg, arrival_taxi_avg, arrival_diverted_avg, arrival_distance_avg data by counting flights with target airport as arriving airport\n",
    "unpleasant_2018_arrival = pd.DataFrame()\n",
    "unpleasant_2018_arrival['total_arrival'] = delay_2018_df.loc[:,[\"DEST\"]].groupby('DEST').size()\n",
    "unpleasant_2018_arrival[[\"arrival_delay_avg\",\"arrival_taxi_avg\"]] = delay_2018_df.loc[:,[\"DEST\",\"ARR_DELAY\",\"TAXI_IN\"]].groupby('DEST').mean()\n",
    "unpleasant_2018_arrival['arrival_diverted_avg'] = delay_2018_df.loc[:,[\"DEST\",\"DIVERTED\"]].groupby('DEST').mean()\n",
    "unpleasant_2018_arrival['arrival_distance_avg'] = delay_2018_df.loc[:,[\"DEST\",\"DISTANCE\"]].groupby('DEST').mean()\n",
    "\n",
    "# Merge all departure and arrival info and select all airports with complete departure and arrival attributes. Save them in delay_2018_df\n",
    "delay_2018_df = unpleasant_2018_departure.merge(unpleasant_2018_arrival,left_index=True,right_index=True)\n",
    "delay_2018_df.index.names = [\"airport_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_departure</th>\n",
       "      <th>departure_delay_avg</th>\n",
       "      <th>departure_taxi_avg</th>\n",
       "      <th>departure_cancelled_avg</th>\n",
       "      <th>departure_distance_avg</th>\n",
       "      <th>total_arrival</th>\n",
       "      <th>arrival_delay_avg</th>\n",
       "      <th>arrival_taxi_avg</th>\n",
       "      <th>arrival_diverted_avg</th>\n",
       "      <th>arrival_distance_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airport_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ABE</td>\n",
       "      <td>4168</td>\n",
       "      <td>11.945071</td>\n",
       "      <td>15.095051</td>\n",
       "      <td>0.020873</td>\n",
       "      <td>619.573417</td>\n",
       "      <td>4165</td>\n",
       "      <td>5.558260</td>\n",
       "      <td>5.037680</td>\n",
       "      <td>0.004562</td>\n",
       "      <td>619.518367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABI</td>\n",
       "      <td>2022</td>\n",
       "      <td>8.027259</td>\n",
       "      <td>13.506310</td>\n",
       "      <td>0.020277</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>2022</td>\n",
       "      <td>5.784016</td>\n",
       "      <td>3.747347</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABQ</td>\n",
       "      <td>24047</td>\n",
       "      <td>8.635997</td>\n",
       "      <td>12.688534</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>678.490456</td>\n",
       "      <td>24048</td>\n",
       "      <td>5.599697</td>\n",
       "      <td>5.385894</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>678.586452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABR</td>\n",
       "      <td>745</td>\n",
       "      <td>7.742198</td>\n",
       "      <td>19.377205</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>745</td>\n",
       "      <td>3.716621</td>\n",
       "      <td>4.771739</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABY</td>\n",
       "      <td>1018</td>\n",
       "      <td>15.052261</td>\n",
       "      <td>15.779543</td>\n",
       "      <td>0.010806</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>1018</td>\n",
       "      <td>10.642137</td>\n",
       "      <td>3.673287</td>\n",
       "      <td>0.006876</td>\n",
       "      <td>145.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              total_departure  departure_delay_avg  departure_taxi_avg  \\\n",
       "airport_code                                                             \n",
       "ABE                      4168            11.945071           15.095051   \n",
       "ABI                      2022             8.027259           13.506310   \n",
       "ABQ                     24047             8.635997           12.688534   \n",
       "ABR                       745             7.742198           19.377205   \n",
       "ABY                      1018            15.052261           15.779543   \n",
       "\n",
       "              departure_cancelled_avg  departure_distance_avg  total_arrival  \\\n",
       "airport_code                                                                   \n",
       "ABE                          0.020873              619.573417           4165   \n",
       "ABI                          0.020277              158.000000           2022   \n",
       "ABQ                          0.009897              678.490456          24048   \n",
       "ABR                          0.010738              257.000000            745   \n",
       "ABY                          0.010806              145.000000           1018   \n",
       "\n",
       "              arrival_delay_avg  arrival_taxi_avg  arrival_diverted_avg  \\\n",
       "airport_code                                                              \n",
       "ABE                    5.558260          5.037680              0.004562   \n",
       "ABI                    5.784016          3.747347              0.000989   \n",
       "ABQ                    5.599697          5.385894              0.001747   \n",
       "ABR                    3.716621          4.771739              0.002685   \n",
       "ABY                   10.642137          3.673287              0.006876   \n",
       "\n",
       "              arrival_distance_avg  \n",
       "airport_code                        \n",
       "ABE                     619.518367  \n",
       "ABI                     158.000000  \n",
       "ABQ                     678.586452  \n",
       "ABR                     257.000000  \n",
       "ABY                     145.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_2018_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By extracting 'departure_delay_avg', 'arrival_delay_avg', 'departure_cancelled_avg' and 'arrival_diverted_avg' columns in `delay_2018_df`, we get all columns of `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departure_delay_avg</th>\n",
       "      <th>arrival_delay_avg</th>\n",
       "      <th>departure_cancelled_avg</th>\n",
       "      <th>arrival_diverted_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airport_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ABE</td>\n",
       "      <td>11.945071</td>\n",
       "      <td>5.558260</td>\n",
       "      <td>0.020873</td>\n",
       "      <td>0.004562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABI</td>\n",
       "      <td>8.027259</td>\n",
       "      <td>5.784016</td>\n",
       "      <td>0.020277</td>\n",
       "      <td>0.000989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABQ</td>\n",
       "      <td>8.635997</td>\n",
       "      <td>5.599697</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABR</td>\n",
       "      <td>7.742198</td>\n",
       "      <td>3.716621</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>0.002685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABY</td>\n",
       "      <td>15.052261</td>\n",
       "      <td>10.642137</td>\n",
       "      <td>0.010806</td>\n",
       "      <td>0.006876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              departure_delay_avg  arrival_delay_avg  departure_cancelled_avg  \\\n",
       "airport_code                                                                    \n",
       "ABE                     11.945071           5.558260                 0.020873   \n",
       "ABI                      8.027259           5.784016                 0.020277   \n",
       "ABQ                      8.635997           5.599697                 0.009897   \n",
       "ABR                      7.742198           3.716621                 0.010738   \n",
       "ABY                     15.052261          10.642137                 0.010806   \n",
       "\n",
       "              arrival_diverted_avg  \n",
       "airport_code                        \n",
       "ABE                       0.004562  \n",
       "ABI                       0.000989  \n",
       "ABQ                       0.001747  \n",
       "ABR                       0.002685  \n",
       "ABY                       0.006876  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = delay_2018_df[[\"departure_delay_avg\", \"arrival_delay_avg\", \"departure_cancelled_avg\", \"arrival_diverted_avg\"]]\n",
    "\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can conclude that there are 358 airports in the U.S. with complete outcome variables for the research question. Save airport codes of these airports (indices of `Y`) in `unpleasant_airport_code_df`. Then, when finding data of `X`, we only need to care about airports in `unpleasant_airport_code_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airport_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WYS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>YAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>YNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>YUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [ABE, ABI, ABQ, ABR, ABY, ACK, ACT, ACV, ACY, ADK, ADQ, AEX, AGS, AKN, ALB, ALO, AMA, ANC, APN, ART, ASE, ATL, ATW, AUS, AVL, AVP, AZA, AZO, BDL, BET, BFF, BFL, BGM, BGR, BHM, BIL, BIS, BJI, BKG, BLI, BLV, BMI, BNA, BOI, BOS, BPT, BQK, BQN, BRD, BRO, BRW, BTM, BTR, BTV, BUF, BUR, BWI, BZN, CAE, CAK, CDC, CDV, CGI, CHA, CHO, CHS, CID, CIU, CKB, CLE, CLL, CLT, CMH, CMI, CMX, CNY, COD, COS, COU, CPR, CRP, CRW, CSG, CVG, CWA, CYS, DAB, DAL, DAY, DBQ, DCA, DEN, DFW, DHN, DLG, DLH, DRO, DRT, DSM, DTW, ...]\n",
       "\n",
       "[358 rows x 0 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpleasant_airport_code_df = Y[[]]\n",
    "\n",
    "unpleasant_airport_code_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of columns in `delay_2018_df` are features of `merged_X`. Let's save them to `X` temporarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract X features\n",
    "X = pd.DataFrame()\n",
    "X[[\"total_departure\",\"total_arrival\", \"departure_distance_avg\",\"arrival_distance_avg\",\"departure_taxi_avg\",\"arrival_taxi_avg\"]] \\\n",
    "= delay_2018_df.loc[:,[\"total_departure\",\"total_arrival\",\"departure_distance_avg\",\"arrival_distance_avg\",\"departure_taxi_avg\",\"arrival_taxi_avg\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_departure</th>\n",
       "      <th>total_arrival</th>\n",
       "      <th>departure_distance_avg</th>\n",
       "      <th>arrival_distance_avg</th>\n",
       "      <th>departure_taxi_avg</th>\n",
       "      <th>arrival_taxi_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airport_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ABE</td>\n",
       "      <td>4168</td>\n",
       "      <td>4165</td>\n",
       "      <td>619.573417</td>\n",
       "      <td>619.518367</td>\n",
       "      <td>15.095051</td>\n",
       "      <td>5.037680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABI</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>13.506310</td>\n",
       "      <td>3.747347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABQ</td>\n",
       "      <td>24047</td>\n",
       "      <td>24048</td>\n",
       "      <td>678.490456</td>\n",
       "      <td>678.586452</td>\n",
       "      <td>12.688534</td>\n",
       "      <td>5.385894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABR</td>\n",
       "      <td>745</td>\n",
       "      <td>745</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>19.377205</td>\n",
       "      <td>4.771739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABY</td>\n",
       "      <td>1018</td>\n",
       "      <td>1018</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>15.779543</td>\n",
       "      <td>3.673287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              total_departure  total_arrival  departure_distance_avg  \\\n",
       "airport_code                                                           \n",
       "ABE                      4168           4165              619.573417   \n",
       "ABI                      2022           2022              158.000000   \n",
       "ABQ                     24047          24048              678.490456   \n",
       "ABR                       745            745              257.000000   \n",
       "ABY                      1018           1018              145.000000   \n",
       "\n",
       "              arrival_distance_avg  departure_taxi_avg  arrival_taxi_avg  \n",
       "airport_code                                                              \n",
       "ABE                     619.518367           15.095051          5.037680  \n",
       "ABI                     158.000000           13.506310          3.747347  \n",
       "ABQ                     678.586452           12.688534          5.385894  \n",
       "ABR                     257.000000           19.377205          4.771739  \n",
       "ABY                     145.000000           15.779543          3.673287  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 'city_name', 'code4', 'latitude', 'longitude' and 'attitude_ft' of `merged_X`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `datasets/original/airport/airports-extended.csv`. Select useful columns of U.S. airports. Drop rows with NaN value.\n",
    "\n",
    "Note that we need 4-digit airport code ('code4') is important since airports are represented by their 4-digit airport codes in runways data, so we can only extract runways data with 'code4' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>country</th>\n",
       "      <th>airport_code</th>\n",
       "      <th>code4</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>altitude_ft</th>\n",
       "      <th>UTC_offset</th>\n",
       "      <th>DST</th>\n",
       "      <th>timezone</th>\n",
       "      <th>type</th>\n",
       "      <th>information_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Goroka Airport</td>\n",
       "      <td>Goroka</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>GKA</td>\n",
       "      <td>AYGA</td>\n",
       "      <td>-6.081690</td>\n",
       "      <td>145.391998</td>\n",
       "      <td>5282</td>\n",
       "      <td>10</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Madang Airport</td>\n",
       "      <td>Madang</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>MAG</td>\n",
       "      <td>AYMD</td>\n",
       "      <td>-5.207080</td>\n",
       "      <td>145.789001</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Mount Hagen Kagamuga Airport</td>\n",
       "      <td>Mount Hagen</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>HGU</td>\n",
       "      <td>AYMH</td>\n",
       "      <td>-5.826790</td>\n",
       "      <td>144.296005</td>\n",
       "      <td>5388</td>\n",
       "      <td>10</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Nadzab Airport</td>\n",
       "      <td>Nadzab</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>LAE</td>\n",
       "      <td>AYNZ</td>\n",
       "      <td>-6.569803</td>\n",
       "      <td>146.725977</td>\n",
       "      <td>239</td>\n",
       "      <td>10</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Port Moresby Jacksons International Airport</td>\n",
       "      <td>Port Moresby</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>POM</td>\n",
       "      <td>AYPY</td>\n",
       "      <td>-9.443380</td>\n",
       "      <td>147.220001</td>\n",
       "      <td>146</td>\n",
       "      <td>10</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                         name     city_name  \\\n",
       "0   1                               Goroka Airport        Goroka   \n",
       "1   2                               Madang Airport        Madang   \n",
       "2   3                 Mount Hagen Kagamuga Airport   Mount Hagen   \n",
       "3   4                               Nadzab Airport        Nadzab   \n",
       "4   5  Port Moresby Jacksons International Airport  Port Moresby   \n",
       "\n",
       "            country airport_code code4  latitude   longitude  altitude_ft  \\\n",
       "0  Papua New Guinea          GKA  AYGA -6.081690  145.391998         5282   \n",
       "1  Papua New Guinea          MAG  AYMD -5.207080  145.789001           20   \n",
       "2  Papua New Guinea          HGU  AYMH -5.826790  144.296005         5388   \n",
       "3  Papua New Guinea          LAE  AYNZ -6.569803  146.725977          239   \n",
       "4  Papua New Guinea          POM  AYPY -9.443380  147.220001          146   \n",
       "\n",
       "  UTC_offset DST              timezone     type information_source  \n",
       "0         10   U  Pacific/Port_Moresby  airport        OurAirports  \n",
       "1         10   U  Pacific/Port_Moresby  airport        OurAirports  \n",
       "2         10   U  Pacific/Port_Moresby  airport        OurAirports  \n",
       "3         10   U  Pacific/Port_Moresby  airport        OurAirports  \n",
       "4         10   U  Pacific/Port_Moresby  airport        OurAirports  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_loc_df = pd.read_csv(\"datasets/original/airport/airports-extended.csv\", names=[\"ID\",\"name\",\"city_name\",\"country\",\"airport_code\",\"code4\",\"latitude\",\"longitude\",\"altitude_ft\",\"UTC_offset\",\"DST\",\"timezone\",\"type\",\"information_source\"])\n",
    "\n",
    "airport_loc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>code4</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>altitude_ft</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airport_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>BTI</td>\n",
       "      <td>Barter Island</td>\n",
       "      <td>PABA</td>\n",
       "      <td>70.134003</td>\n",
       "      <td>-143.582001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>K03</td>\n",
       "      <td>Fort Wainwright</td>\n",
       "      <td>PAWT</td>\n",
       "      <td>70.613403</td>\n",
       "      <td>-159.860001</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LUR</td>\n",
       "      <td>Cape Lisburne</td>\n",
       "      <td>PALU</td>\n",
       "      <td>68.875099</td>\n",
       "      <td>-166.110001</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PIZ</td>\n",
       "      <td>Point Lay</td>\n",
       "      <td>PPIZ</td>\n",
       "      <td>69.732903</td>\n",
       "      <td>-163.005005</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ITO</td>\n",
       "      <td>Hilo</td>\n",
       "      <td>PHTO</td>\n",
       "      <td>19.721399</td>\n",
       "      <td>-155.048004</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    city_name code4   latitude   longitude  altitude_ft\n",
       "airport_code                                                           \n",
       "BTI             Barter Island  PABA  70.134003 -143.582001            2\n",
       "K03           Fort Wainwright  PAWT  70.613403 -159.860001           35\n",
       "LUR             Cape Lisburne  PALU  68.875099 -166.110001           16\n",
       "PIZ                 Point Lay  PPIZ  69.732903 -163.005005           22\n",
       "ITO                      Hilo  PHTO  19.721399 -155.048004           38"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_loc_df = airport_loc_df[airport_loc_df[\"country\"]==\"United States\"]\n",
    "airport_loc_df = airport_loc_df.loc[:,[\"city_name\",\"airport_code\",\"code4\", \"latitude\",\"longitude\",\"altitude_ft\"]]\n",
    "airport_loc_df = airport_loc_df[airport_loc_df[\"airport_code\"]!=\"\\\\N\"]\n",
    "airport_loc_df = airport_loc_df.set_index(\"airport_code\")\n",
    "\n",
    "airport_loc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply the function clean_city_name to standardize the 'city_name' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_city_name(input_city):\n",
    "    original = input_city\n",
    "    input_city = str(input_city)\n",
    "    input_city = input_city.strip()\n",
    "    input_city = input_city.lower()\n",
    "    \n",
    "    input_city = input_city.replace(\".\",\"\")\n",
    "    input_city = input_city.replace(\"\\\\\\\\\",\"\")\n",
    "    input_city = input_city.replace(\"-\",\" \")\n",
    "    input_city = input_city.replace(\" - \",\" \")\n",
    "    input_city = input_city.replace(\"saint \",\"st\")\n",
    "    input_city = input_city.replace(\"east \",\"\")\n",
    "    input_city = input_city.replace(\"west \",\"\")\n",
    "    \n",
    "    input_city = input_city.translate({ord(k): None for k in digits})\n",
    "    \n",
    "    if ('/' in input_city):\n",
    "        input_city = input_city[:input_city.find('/')] # in case city have muitiple names like \"cityname1/cityname2\"\n",
    "    if ('(' in input_city):\n",
    "        input_city = input_city[:input_city.find('(')] # Same as above\n",
    "    if (',' in input_city):\n",
    "        input_city = input_city[:input_city.find(',')] \n",
    "    input_city = input_city.strip()   \n",
    "    if (' ' in input_city):\n",
    "        temp=input_city.find(' ')\n",
    "        if (temp > 2):\n",
    "            input_city = input_city[:input_city.find(' ')]\n",
    "        else:\n",
    "            if (input_city.find(' ',temp+1) != -1):\n",
    "                input_city = input_city[temp+1:input_city.find(' ',temp+1)]\n",
    "            else:\n",
    "                input_city = input_city[temp+1:]\n",
    "    input_city = input_city.strip()\n",
    "    try:\n",
    "        assert len(input_city) > 2\n",
    "        assert input_city.replace(\" \",\"\").replace(\"'\",\"\").isalpha()\n",
    "    except:\n",
    "        #print(\"This city name is prehaps incorrect: \",original,input_city,len(original))\n",
    "        1+1\n",
    "    return input_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>code4</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>altitude_ft</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airport_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>BTI</td>\n",
       "      <td>barter</td>\n",
       "      <td>PABA</td>\n",
       "      <td>70.134003</td>\n",
       "      <td>-143.582001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>K03</td>\n",
       "      <td>fort</td>\n",
       "      <td>PAWT</td>\n",
       "      <td>70.613403</td>\n",
       "      <td>-159.860001</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LUR</td>\n",
       "      <td>cape</td>\n",
       "      <td>PALU</td>\n",
       "      <td>68.875099</td>\n",
       "      <td>-166.110001</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PIZ</td>\n",
       "      <td>point</td>\n",
       "      <td>PPIZ</td>\n",
       "      <td>69.732903</td>\n",
       "      <td>-163.005005</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ITO</td>\n",
       "      <td>hilo</td>\n",
       "      <td>PHTO</td>\n",
       "      <td>19.721399</td>\n",
       "      <td>-155.048004</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XMR</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>KXMR</td>\n",
       "      <td>28.467600</td>\n",
       "      <td>-80.566597</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ZZV</td>\n",
       "      <td>zanesville</td>\n",
       "      <td>KZZV</td>\n",
       "      <td>39.944401</td>\n",
       "      <td>-81.892097</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ENN</td>\n",
       "      <td>nenana</td>\n",
       "      <td>PANN</td>\n",
       "      <td>64.547302</td>\n",
       "      <td>-149.074005</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WWA</td>\n",
       "      <td>wasilla</td>\n",
       "      <td>PAWS</td>\n",
       "      <td>61.571701</td>\n",
       "      <td>-149.539993</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DIC</td>\n",
       "      <td>dicka</td>\n",
       "      <td>DICK</td>\n",
       "      <td>37.789000</td>\n",
       "      <td>-122.430000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1648 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               city_name code4   latitude   longitude  altitude_ft\n",
       "airport_code                                                      \n",
       "BTI               barter  PABA  70.134003 -143.582001            2\n",
       "K03                 fort  PAWT  70.613403 -159.860001           35\n",
       "LUR                 cape  PALU  68.875099 -166.110001           16\n",
       "PIZ                point  PPIZ  69.732903 -163.005005           22\n",
       "ITO                 hilo  PHTO  19.721399 -155.048004           38\n",
       "...                  ...   ...        ...         ...          ...\n",
       "XMR                cocoa  KXMR  28.467600  -80.566597           10\n",
       "ZZV           zanesville  KZZV  39.944401  -81.892097          900\n",
       "ENN               nenana  PANN  64.547302 -149.074005          362\n",
       "WWA              wasilla  PAWS  61.571701 -149.539993          354\n",
       "DIC                dicka  DICK  37.789000 -122.430000            0\n",
       "\n",
       "[1648 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_loc_df[\"city_name\"] = airport_loc_df[\"city_name\"].apply(clean_city_name)# clean city name\n",
    "\n",
    "airport_loc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cities_df = pd.read_csv(\"datasets/original/city/uscities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kept latitude and longitude to differentiate cities with same name\n",
    "us_cities_df = us_cities_df[[\"city\",\"state_id\",\"county_fips\",\"county_name\",\"population\",\"lat\",\"lng\"]] \n",
    "us_cities_df = us_cities_df.rename(columns = {\"city\":\"city_name\"})                                              \n",
    "us_cities_df[\"fips\"] = us_cities_df[\"county_fips\"]\n",
    "\n",
    "def get_county_code(input_county):\n",
    "    return int(input_county) % 1000\n",
    "\n",
    "us_cities_df[\"county_fips\"] = us_cities_df[\"county_fips\"].apply(get_county_code)\n",
    "us_cities_df[\"city_name\"] = us_cities_df[\"city_name\"].apply(clean_city_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_prop_df = unpleasant_airport_code_df.merge(airport_loc_df,how='inner',left_index=True,right_index=True)\n",
    "\n",
    "city_search_df = pd.DataFrame(columns=[\"airport_code\",\"state_id\",\"county_id\",\"city_id\",\"fips\",\"population\"])\n",
    "for ind,row in airport_prop_df.iterrows():\n",
    "    city = row[\"city_name\"]\n",
    "    target_lat = row[\"latitude\"]\n",
    "    target_lng = row[\"longitude\"]\n",
    "    try:      \n",
    "        target_cities = us_cities_df[us_cities_df[\"city_name\"]==city]\n",
    "        \n",
    "        if not (target_cities.shape[0] == 1): # If there are multiple city with same name\n",
    "            def calc_dis(input_):\n",
    "                err = abs(target_lat - input_[\"lat\"]) + abs(target_lng - input_[\"lng\"])\n",
    "                return err\n",
    "            target_cities.loc[:,\"error\"] = (target_cities.apply(calc_dis,axis=1))\n",
    "            target_city = target_cities.sort_values(by=\"error\").iloc[0]\n",
    "            \n",
    "            assert target_city[\"error\"] < 1.5 # assert the error should be <1.5 degs ~ 40 miles.\n",
    "            \n",
    "            target_city = target_city.drop([\"error\"])\n",
    "        elif (target_cities.shape[0] >= 1):\n",
    "            target_city = target_cities.iloc[0]\n",
    "        \n",
    "        county = str(target_city[\"county_fips\"])\n",
    "        if (len(county)==1):\n",
    "            county = \"00\" + county\n",
    "        elif (len(county)==2):\n",
    "            county = \"0\" + county\n",
    "\n",
    "        city_search_df = city_search_df.append({\"airport_code\":ind,\"state_id\":target_city[\"state_id\"],\"county_id\":county,\"city_id\":target_city.name,\"fips\":target_city[\"fips\"],\"population\":target_city[\"population\"]},ignore_index=True)        \n",
    "    except:\n",
    "        try:\n",
    "            def calc_dis(input_):\n",
    "                err = abs(target_lat - input_[\"lat\"]) + abs(target_lng - input_[\"lng\"])\n",
    "                return err\n",
    "            us_cities_df_copy = us_cities_df\n",
    "            us_cities_df_copy.loc[:,\"error\"] = (us_cities_df.apply(calc_dis,axis=1))\n",
    "            target_city = us_cities_df_copy.sort_values(by=\"error\").iloc[0]\n",
    "            assert target_city[\"error\"] < 1.5\n",
    "            county = str(target_city[\"county_fips\"])\n",
    "            if (len(county)==1):\n",
    "                county = \"00\" + county\n",
    "            elif (len(county)==2):\n",
    "                county = \"0\" + county\n",
    "            city_search_df = city_search_df.append({\"airport_code\":ind,\"state_id\":target_city[\"state_id\"],\"county_id\":county,\"city_id\":target_city.name,\"fips\":target_city[\"fips\"],\"population\":target_city[\"population\"]},ignore_index=True)\n",
    "        except:\n",
    "            print(\"No data for \",city)\n",
    "            city_search_df = city_search_df.append({\"airport_code\":ind,\"state_id\":np.nan,\"county_id\":np.nan,\"city_id\":np.nan,\"fips\":np.nan,\"population\":np.nan},ignore_index=True)\n",
    "\n",
    "#special case for DC\n",
    "for ind,row in city_search_df.iterrows():\n",
    "    if (row[\"airport_code\"]==\"DCA\"):\n",
    "        city_search_df.iloc[ind][\"state_id\"]=\"MD\"\n",
    "        city_search_df.iloc[ind][\"county_id\"]=\"511\"\n",
    "\n",
    "# Remove Hawaii and Alaska\n",
    "city_search_df = city_search_df[(city_search_df[\"state_id\"]!=\"HI\") & (city_search_df[\"state_id\"]!=\"AK\")]\n",
    "airport_prop_df = airport_prop_df.merge(city_search_df.set_index(\"airport_code\").loc[:,[\"city_id\",\"fips\",\"population\"]],left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_search_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_prop_df # prop: property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_climate_data(state,county,year):\n",
    "    save_path = \"datasets/original/weather/\"\n",
    "    fname = state + county + \"_\" + str(year) + \".csv\"\n",
    "    if (len(glob.glob(save_path + fname))==0):\n",
    "        URL = \"https://www.ncdc.noaa.gov/cag/county/time-series/{}-{}-{}-all-1-2000-2020.csv?base_prd=true&begbaseyear=1901&endbaseyear=2000\".format(state,county,\"tavg\")\n",
    "        r = requests.get(URL)\n",
    "        file = wget.download(URL,out=save_path + \"tavg/tavg_\" + fname)\n",
    "        URL = \"https://www.ncdc.noaa.gov/cag/county/time-series/{}-{}-{}-all-1-2000-2020.csv?base_prd=true&begbaseyear=1901&endbaseyear=2000\".format(state,county,\"pcp\")\n",
    "        r = requests.get(URL)\n",
    "        file = wget.download(URL,out=save_path + \"pcp/pcp_\" + fname)\n",
    "\n",
    "        tavg_df = pd.read_csv(save_path + \"tavg/tavg_\" + fname).iloc[4:]\n",
    "        tavg_df.columns=[\"date\",\"tavg\",\"comp\"]\n",
    "        tavg = tavg_df.set_index(\"date\")[\"tavg\"]\n",
    "\n",
    "        pcp_df = pd.read_csv(save_path + \"pcp/pcp_\" + fname).iloc[4:]\n",
    "        pcp_df.columns=[\"date\",\"pcp\",\"comp\"]\n",
    "        pcp = pcp_df.set_index(\"date\")[\"pcp\"]\n",
    "\n",
    "        pd.concat([tavg, pcp], axis=1).to_csv(save_path + fname)\n",
    "        time.sleep(1) # not requesting too frequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "# Download data according to city_search_df\n",
    "for ind,row in city_search_df.iterrows():\n",
    "    try:\n",
    "        download_climate_data(row[\"state_id\"],row[\"county_id\"],2018)\n",
    "#        download_climate_data(row[\"state_id\"],row[\"county_id\"],2019)\n",
    "    except:\n",
    "        print(row)\n",
    "    counter+=1\n",
    "    print(\"progress: {:.2f}%   Just done: {}\".format(100 * counter / city_search_df.shape[0],row[\"airport_code\"]),end=\"\\r\")\n",
    "\n",
    "# Process downloaded data\n",
    "temp_pcp_df = pd.DataFrame(columns=[\"airport_code\",\"temp_avg\",\"pcp_avg\"])\n",
    "for ind,row in city_search_df.iterrows():\n",
    "    state = row[\"state_id\"]\n",
    "    county = row[\"county_id\"]\n",
    "    save_path = \"datasets/original/weather/\"\n",
    "    \n",
    "    try:\n",
    "        fname = state + county + \"_2018.csv\" # change it to 2018 only --YD\n",
    "        temp_pcp = pd.read_csv(save_path + fname)\n",
    "        tavg = temp_pcp.mean()[\"tavg\"]\n",
    "        pcp = temp_pcp.mean()[\"pcp\"]\n",
    "        \n",
    "        temp_pcp_df = temp_pcp_df.append({\"airport_code\":row[\"airport_code\"],\"temp_avg\":tavg,\"pcp_avg\":pcp},ignore_index=True)\n",
    "        \n",
    "    except:\n",
    "        temp_pcp_df = temp_pcp_df.append({\"airport_code\":row[\"airport_code\"],\"temp_avg\":np.nan,\"pcp_avg\":np.nan},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_prop_df = airport_prop_df.merge(temp_pcp_df.set_index(\"airport_code\"),left_index=True,right_index=True)\n",
    "airport_prop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_strike_df = pd.read_excel(\"datasets/original/airport/Bird Strikes.xlsx\") #data6\n",
    "airport_name_df = pd.read_excel(\"datasets/original/airport/airportcode.xlsx\") #data7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_strike_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_strike_df = bird_strike_df[[\"Airport: Name\", \"Effect: Indicated Damage\"]]\n",
    "bird_strike_df = bird_strike_df.rename(columns = {\"Airport: Name\": \"airport_name\", \"Effect: Indicated Damage\":\"bird_strike_effect\"})\n",
    "bird_strike_df = bird_strike_df.dropna()\n",
    "bird_strike_df = bird_strike_df.reset_index(drop = True)\n",
    "bird_strike_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_name_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_name_df = airport_name_df.dropna()\n",
    "airport_name_df = airport_name_df.reset_index(drop = True)\n",
    "airport_name_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_airport_name(string):\n",
    "    \n",
    "    string = string.lower()\n",
    "    string = string.strip()\n",
    "    if 'intl' in string:\n",
    "        string = string.replace('intl', '')\n",
    "    if 'arpt' in string:\n",
    "        string = string.replace('arpt', '')\n",
    "    if 'regional' in string:\n",
    "        string = string.replace('regional', '')\n",
    "    if 'airport' in string:\n",
    "        string = string.replace('airport', '')\n",
    "    if 'sunport' in string:\n",
    "        string = string.replace('sunport', '')\n",
    "    if 'international' in string:\n",
    "        string = string.replace('international', '')\n",
    "    if 'intercontinental' in string:\n",
    "        string = string.replace('intercontinental', '')\n",
    "    else:\n",
    "        output = string\n",
    "        \n",
    "    string = string = string.strip()\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_strike_df['airport_name'] = bird_strike_df['airport_name'].apply(standardize_airport_name)\n",
    "airport_name_df['airport_name'] = airport_name_df['airport_name'].apply(standardize_airport_name)\n",
    "\n",
    "def check_strike (string):\n",
    "    return 1\n",
    "\n",
    "def check_damage (string):\n",
    "    if 'Caused' in string:\n",
    "        output = 1\n",
    "    else:\n",
    "        output = 0\n",
    "    return output\n",
    "\n",
    "bird_strike_df['strike'] = bird_strike_df['bird_strike_effect'].apply(check_strike)\n",
    "bird_strike_df['damage'] = bird_strike_df['bird_strike_effect'].apply(check_damage)\n",
    "bird_strike_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_strike = bird_strike_df.groupby('airport_name').agg({'strike':['sum']})\n",
    "grouped_strike = grouped_strike.reset_index()\n",
    "grouped_damage = bird_strike_df.groupby('airport_name').agg({'damage':['sum']})\n",
    "\n",
    "bird_strike_sum_df = pd.merge(grouped_strike, grouped_damage, on='airport_name')\n",
    "bird_strike_sum_df.columns = ['airport_name', 'strike_sum','damage_sum']\n",
    "\n",
    "bird_strike_avg_df = pd.merge(airport_name_df, bird_strike_sum_df, on='airport_name')\n",
    "\n",
    "def average_sum(input):\n",
    "    output = input/(2011 - 2000 + 1)\n",
    "    return output\n",
    "\n",
    "bird_strike_avg_df['strike_avg'] = bird_strike_avg_df['strike_sum'].apply(average_sum)\n",
    "bird_strike_avg_df['damage_avg'] = bird_strike_avg_df['damage_sum'].apply(average_sum)\n",
    "bird_strike_avg_df = bird_strike_avg_df.drop(columns = ['strike_sum', 'damage_sum'])\n",
    "\n",
    "bird_strike_avg_df= bird_strike_avg_df.drop(columns = [\"airport_name\"])\n",
    "bird_strike_avg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We later need to merge this dataframe to `airport_prop_df`. However, not all airports have bird strike. Therefore, we used a right merge(that kept all rows from `airport_prop_df`) and filled nan with 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_strike_final_df = pd.merge(bird_strike_avg_df, unpleasant_airport_code_df.reset_index(), how='right')\n",
    "# unpleasant_airport_code_df have the same index as airport_prop_df\n",
    "bird_strike_final_df = bird_strike_final_df.fillna(0)\n",
    "bird_strike_final_df = bird_strike_final_df.set_index(\"airport_code\")\n",
    "bird_strike_final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_runways_df=pd.read_csv(\"datasets/original/airport/runways.csv\")\n",
    "\n",
    "airport_runways_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_runways_df = airport_runways_df.rename(columns = {\"airport_ident\":\"code4\"})\n",
    "airport_runways_df = pd.merge(airport_runways_df, airport_loc_df.reset_index(), how = 'inner', on = 'code4')\n",
    "airport_runways_df = airport_runways_df[[\"code4\", \"airport_code\", \"length_ft\", \"width_ft\"]]\n",
    "airport_runways_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runways_sum_df = airport_runways_df.groupby(['airport_code']).sum()\n",
    "runways_mean_df = airport_runways_df.groupby(['airport_code']).mean()\n",
    "runways_count_df = airport_runways_df.groupby(['airport_code']).count()\n",
    "runway_final_df = runways_sum_df[\"length_ft\"].to_frame().join(runways_mean_df[\"width_ft\"].to_frame())\n",
    "runway_final_df[\"count\"] = runways_count_df[\"length_ft\"]\n",
    "runway_final_df.columns = [\"length_ft_sum\", \"width_ft_avg\",\"runway_count\"]\n",
    "\n",
    "runway_final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enplanements_df = pd.read_excel('datasets/original/city/commercial_service_enplanements.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enplanements_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enplanements_df = enplanements_df.rename(columns = {\"Locid\":\"airport_code\",\"CY 18 Enplanements\":\"enplanements\"})\n",
    "enplanements_df = enplanements_df.set_index(\"airport_code\")\n",
    "enplanements_df = enplanements_df[[\"enplanements\"]] # change it to only 2018 --YD\n",
    "\n",
    "enplanements_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_df = pd.read_excel(\"datasets/original/airport/security_wait_times.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_df = security_df.fillna(0)\n",
    "security_df = security_df.rename(columns={\"Code\":\"airport_code\"})\n",
    "security_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_df[\"security_avg\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_security_avg(df):\n",
    "    for index,row in df.iterrows():\n",
    "        row_sub = row[3:128]\n",
    "        time = 0\n",
    "        sums = 0\n",
    "        for i in row_sub:\n",
    "            if i>0:\n",
    "                time = time + 1\n",
    "                sums = sums + i\n",
    "        df.at[index,\"security_avg\"] = sums/time\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_df = calculate_security_avg(security_df)\n",
    "security_df = security_df[[\"airport_code\", \"security_avg\"]].groupby(\"airport_code\").sum()\n",
    "security_df = security_df.drop(0)\n",
    "security_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_df = pd.concat([security_df, unpleasant_airport_code_df], axis=1, sort=False)\n",
    "security_df = security_df.dropna()\n",
    "security_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Cleaning step: merging all dataframes together to get X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_X_df = pd.concat([X,airport_prop_df, bird_strike_final_df, enplanements_df, runway_final_df, security_df], axis=1, sort=False)\n",
    "merged_X_df = merged_X_df.dropna()\n",
    "merged_X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_X_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = delay_2018_df[[\"departure_delay_avg\", \"arrival_delay_avg\", \"departure_cancelled_avg\", \"arrival_diverted_avg\"]]\n",
    "Y = Y.merge(merged_X_df[[]],how=\"right\",left_index=True,right_index=True)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_X_df.to_csv(\"datasets/merged/merged_X.csv\")\n",
    "Y.to_csv(\"datasets/merged/Y.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
